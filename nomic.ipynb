{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ced8e8e-912a-4ed8-93d9-e73748dd61c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading API keys...\n",
      "INFO:__main__:Initializing the embed model...\n",
      "INFO:__main__:Initializing the llm...\n",
      "INFO:__main__:Load existing index from persisted storage...\n",
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "INFO:__main__:Apply the given template...\n",
      "INFO:__main__:Queriying the index...\n",
      "INFO:__main__:Ready to accept a question...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Broadcast in the context of Distributed Systems refers to a scenario where a processor wants to send a message to all other processors in the network. This is typically done efficiently by utilizing a spanning tree structure, where the message is propagated from the root processor to all its children, and then further down the tree until all processors receive the message. The goal of broadcast is to ensure that all processors in the network are informed of the message without redundant deliveries or infinite loops. It is a fundamental concept in information exchange within distributed systems.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script uses the llamaindex framework to recreate the TutorGPT based on the RAG approach and using a LLM.\n",
    "\"\"\"\n",
    "#version: v3.2\n",
    "\n",
    "#Import of libraries\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import os.path\n",
    "import faiss\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.nomic import NomicEmbedding\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    PromptTemplate,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "#Add logging to get a more detailed view on the running code\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger(__name__) #http request\n",
    "\n",
    "logger.info(\"Loading API keys...\")\n",
    "#Access api_key and nomic_api_key from .env-file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "nomic_api_key = os.getenv (\"NOMIC_API_KEY\")\n",
    "\n",
    "logger.info(\"Initializing the embed model...\")\n",
    "#Initialize the embed model\n",
    "embed_model = NomicEmbedding(\n",
    "    api_key=nomic_api_key,\n",
    "    dimensionality=256, #lenght of the vector\n",
    "    model_name=\"nomic-embed-text-v1.5\",\n",
    ")\n",
    "\n",
    "logger.info(\"Initializing the llm...\")\n",
    "#The LLM model, which will be used\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "#Change the llm-model & embedding-model(globally)\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "#Check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    logger.info(\"Creating new index because no persistent storage was found...\")\n",
    "    #Load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "    #Chunk-size and overlap can be adjusted\n",
    "    Settings.chunk_size = 256\n",
    "    Settings.chunk_overlap = 25\n",
    "\n",
    "    #FAISS based vectorstore\n",
    "    d=256 #256 is the dimensionality used for nomic, 1536 is the dimensionality for gpt-3.5-embeddings\n",
    "    faiss_index = faiss.IndexFlatL2(d)\n",
    "    vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "\n",
    "    index = VectorStoreIndex.from_documents(documents=documents, vector_store=vector_store)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    logger.info(\"Load existing index from persisted storage...\")\n",
    "    \n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Create a custom prompt template\n",
    "template = \"\"\"\n",
    "\n",
    "    Your name is \"TutorGPT2.0\". You are an upbeat and encouraging tutor for Distributed Systems. \n",
    "    You help students understand concepts by explaining ideas and answering questions. \n",
    "    You encourage interaction, practice, and creation over passive learning, and help students reflect on their thought processes to generalize skills. \n",
    "    You stimulate interest in learning and strengthen the learner's self-efficacy.\n",
    "    Given the documents as a context (below), help students understand the topic by providing explanations, examples, and analogies.\n",
    "\n",
    "    {context_str}\n",
    "\n",
    "    Introduce yourself as their \"TutorGPT2.0\", ready to help with any questions. Think step by step and reflect on each step before you answer the question:\n",
    "    Follow these principles in your answers:\n",
    "    1. Answer precisely based on the context.\n",
    "    2. Provide credible resources.\n",
    "    3. If you cannot answer a question based on the context, state \"I'm afraid I can't answer that\" and stop.\n",
    "    4. Be correct and honest; do not use false information.\n",
    "    5. Stay on the topic of tutoring and learning.\n",
    "    6. Be relevant and receptive.\n",
    "    7. Do not repeat yourself verbatim.\n",
    "    8. Do not claim to be human or embodied.\n",
    "    9. Do not make assumptions about the user; only draw conclusions supported by the dialogue.\n",
    "    10. Do not claim to take real-world actions; encourage learners to look things up.\n",
    "    11. Be helpful, not evasive.\n",
    "    12. Be harmless.\n",
    "    13. Apply the above points to any other language you can.\n",
    "    14. Answer in the language in which the question is asked.\n",
    "\n",
    "    Answer the question: {query_str}\n",
    "    \"\"\"\n",
    "\n",
    "#Use the template\n",
    "logger.info(\"Apply the given template...\")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "logger.info(\"Queriying the index...\")\n",
    "#Query the index\n",
    "query_engine = index.as_query_engine(similarity_top_k=4, text_qa_template=qa_template)\n",
    "\n",
    "logger.info(\"Ready to accept a question...\")\n",
    "\n",
    "#Ask a question and print the response\n",
    "response = query_engine.query(\"What is broadcast?\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82b7959d-60b6-4651-b781-5ee0f20eaf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b14fd57-bc37-4dee-936a-935c46108e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-nomic in c:\\users\\katha\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: einops<0.8.0,>=0.7.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-embeddings-nomic) (0.7.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-embeddings-nomic) (0.12.3)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface<0.5.0,>=0.4.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-embeddings-nomic) (0.4.0)\n",
      "Requirement already satisfied: nomic<4.0.0,>=3.0.30 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-embeddings-nomic) (3.3.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (2024.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (10.4.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (0.26.3)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (3.3.1)\n",
      "Requirement already satisfied: click in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (8.1.7)\n",
      "Requirement already satisfied: jsonlines in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (0.7.2)\n",
      "Requirement already satisfied: rich in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (13.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (2.2.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (16.1.0)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (2.8.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (24.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (2024.8.30)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (4.46.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (1.13.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\katha\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-nomic) (0.14.0)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from loguru->nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from rich->nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from rich->nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->nomic<4.0.0,>=3.0.30->llama-index-embeddings-nomic) (1.16.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\katha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (0.4.5)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface<0.5.0,>=0.4.0->llama-index-embeddings-nomic) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U llama-index-embeddings-nomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f4586-69ad-465c-8b4e-cd02c0de8552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
