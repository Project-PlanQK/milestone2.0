{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e110c031-4630-4aed-8dd3-f929afdf55d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\katha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\katha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\katha\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.6/203.0 MB 12.5 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 5.2/203.0 MB 12.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 7.9/203.0 MB 12.8 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 10.7/203.0 MB 12.7 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 13.4/203.0 MB 12.7 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 16.3/203.0 MB 12.8 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 18.9/203.0 MB 12.8 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 21.5/203.0 MB 12.8 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 24.1/203.0 MB 12.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 27.0/203.0 MB 12.9 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 29.6/203.0 MB 12.9 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 32.5/203.0 MB 12.8 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 35.1/203.0 MB 12.8 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 37.7/203.0 MB 12.8 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 40.4/203.0 MB 12.8 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 43.0/203.0 MB 12.8 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 45.6/203.0 MB 12.8 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 48.2/203.0 MB 12.9 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 50.9/203.0 MB 12.8 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 53.5/203.0 MB 12.9 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 56.4/203.0 MB 12.9 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 58.7/203.0 MB 12.9 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 61.3/203.0 MB 12.9 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 64.0/203.0 MB 12.9 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 66.6/203.0 MB 12.9 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 69.5/203.0 MB 12.9 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 72.1/203.0 MB 12.9 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 75.0/203.0 MB 12.9 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 77.9/203.0 MB 12.9 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 80.5/203.0 MB 12.9 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 83.1/203.0 MB 12.9 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 86.0/203.0 MB 12.9 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 88.6/203.0 MB 12.8 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 91.2/203.0 MB 12.9 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 94.1/203.0 MB 12.9 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 96.7/203.0 MB 12.9 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 99.4/203.0 MB 12.9 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 102.0/203.0 MB 12.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 104.6/203.0 MB 12.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 107.2/203.0 MB 12.9 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 109.8/203.0 MB 12.9 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 112.7/203.0 MB 12.9 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 115.6/203.0 MB 12.9 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 118.2/203.0 MB 12.9 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 120.8/203.0 MB 12.9 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 123.5/203.0 MB 12.9 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 126.1/203.0 MB 12.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 129.0/203.0 MB 12.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 131.6/203.0 MB 12.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.5/203.0 MB 12.9 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 137.1/203.0 MB 12.9 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 140.0/203.0 MB 12.9 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 142.6/203.0 MB 12.9 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 145.5/203.0 MB 12.9 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 148.1/203.0 MB 12.9 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 150.7/203.0 MB 12.9 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 153.6/203.0 MB 12.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 156.2/203.0 MB 12.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 158.9/203.0 MB 12.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 161.5/203.0 MB 12.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 164.4/203.0 MB 12.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 167.0/203.0 MB 12.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 169.6/203.0 MB 12.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 172.2/203.0 MB 12.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 175.1/203.0 MB 12.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 177.7/203.0 MB 12.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 180.4/203.0 MB 12.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 183.0/203.0 MB 12.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 185.9/203.0 MB 12.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 188.5/203.0 MB 12.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 191.1/203.0 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.7/203.0 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 196.3/203.0 MB 12.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.0/203.0 MB 12.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.9/203.0 MB 12.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 12.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 12.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.0/203.0 MB 12.5 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 12.2 MB/s eta 0:00:00\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 12.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/10.0 MB 13.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.1/10.0 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 12.8 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Using cached tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
      "Installing collected packages: sympy, safetensors, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed huggingface-hub-0.26.3 safetensors-0.4.5 sentence-transformers-3.3.1 sympy-1.13.1 tokenizers-0.20.3 torch-2.5.1 transformers-4.46.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9aba31a-01ea-4568-8951-3ab59f103e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.4.0-py3-none-any.whl.metadata (767 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.26.3)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-embeddings-huggingface) (0.12.2)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-embeddings-huggingface) (3.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.11.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\katha\\anaconda3\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10.5)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.34)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (10.4.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.46.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.11.0)\n",
      "Requirement already satisfied: click in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\katha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\katha\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.3)\n",
      "Downloading llama_index_embeddings_huggingface-0.4.0-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index-embeddings-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82aa88cb-8fcc-4a7a-a029-bd9bff39f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in c:\\users\\katha\\anaconda3\\lib\\site-packages (0.2.16)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.7 (from llama-index-llms-openai)\n",
      "  Using cached llama_index_core-0.11.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-llms-openai) (1.54.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.14.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.7.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\katha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\katha\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (24.1)\n",
      "Using cached llama_index_core-0.11.23-py3-none-any.whl (1.6 MB)\n",
      "Installing collected packages: llama-index-core\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.12.2\n",
      "    Uninstalling llama-index-core-0.12.2:\n",
      "      Successfully uninstalled llama-index-core-0.12.2\n",
      "Successfully installed llama-index-core-0.11.23\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-embeddings-huggingface 0.4.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-vector-stores-faiss 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb5caa3-3342-426b-a001-07e182dfff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setze deinen OpenAI API-Schlüssel\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bbb5be9-8745-4125-a323-41da457e3744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 1.71s\n",
      "Multicast is a form of communication that involves coordination and agreement among group members to receive copies of messages sent to the group. It allows for different delivery guarantees, such as agreeing on the set of messages received or on delivery ordering. Multicast can be achieved through a single operation instead of sending messages individually to each member, which enhances efficiency by sending once on each link and utilizing hardware multicast when available.\n"
     ]
    }
   ],
   "source": [
    "#pip install llama-index-vector-stores-faiss faiss-cpu\n",
    "import os.path\n",
    "import faiss\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "#from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from time import time\n",
    "\n",
    "# check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    Settings.chunk_size = 512\n",
    "    Settings.chunk_overlap = 50\n",
    "    \n",
    "    Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "    Settings.embed_model = HuggingFaceEmbedding(\n",
    "        model_name=\"BAAI/bge-small-en-v1.5\", top_n=3\n",
    "    )\n",
    "\n",
    "    embedding = Settings.embed_model\n",
    "\n",
    "    # Verwende das SentenceTransformer-Modell für Embeddings\n",
    "    embedding = SentenceTransformerEmbedding(model)\n",
    "\n",
    "    # Erstelle den Index mit dem gewählten Embedding-Modell\n",
    "    #index = VectorStoreIndex.from_documents(documents, embedding=embedding)\n",
    "\n",
    "    # Erstellen des FAISS-basierten VectorStore\n",
    "    d=1536\n",
    "    faiss_index = faiss.IndexFlatL2(d)  # 512 ist die Dimension des Embeddings, 1536 für gpt-3.5-embeddings\n",
    "    vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "    # Erstellen des Index mit FAISS als Speichersystem\n",
    "    index = VectorStoreIndex.from_documents(documents=documents, vector_store=vector_store)\n",
    "    #index = VectorStoreIndex.from_documents(documents, )\n",
    "\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Either way we can now query the index\n",
    "#query_engine = index.as_query_engine()\n",
    "#query_engine = index.as_query_engine(similarity_top_k=4)\n",
    "# Definiere die Abfrageengine\n",
    "query_engine = index.as_query_engine(similarity_top_k=4)\n",
    "\n",
    "# Frage ausführen\n",
    "now = time()\n",
    "response = query_engine.query(\"What is multicast?\")\n",
    "print(f\"Elapsed: {round(time() - now, 2)}s\")\n",
    "print(response)\n",
    "#response = query_engine.query(\"Can you please sum up the introduction to multicast?\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47db6376-2e9d-448e-b9ff-44b976eed3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a57c54-5702-4e76-89bf-25dcc770bcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25726ab238d24109b9320c1bffe310e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katha\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\katha\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-2-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea65eafea2b4528a760c86bc9c4bce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/62.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18beca86fd1c46c8b23bfab262fef6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c05efaa8a54daaad8583684e8240ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7b460eb1694215b552db6a55b686db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "rerank = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", top_n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c62210e-e6d5-4baf-9ba2-14f474ae8844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 1.96s\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10, node_postprocessors=[rerank]\n",
    ")\n",
    "\n",
    "now = time()\n",
    "response = query_engine.query(\n",
    "    \"What is multicast?\",\n",
    ")\n",
    "print(f\"Elapsed: {round(time() - now, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a849530-5933-4a99-b6ff-396426673262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 1.96s\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10, node_postprocessors=[rerank]\n",
    ")\n",
    "\n",
    "now = time()\n",
    "response = query_engine.query(\n",
    "    \"What is multicast?\",\n",
    ")\n",
    "print(f\"Elapsed: {round(time() - now, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54a89f75-9542-4860-81ec-d58bd47298f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\katha\\anaconda3\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\katha\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d3bbc3c-47c7-4c31-9146-fafb29372ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 1.58s\n",
      "Multicast is a form of communication that involves coordination and agreement among members of a group to receive copies of messages sent to the group. It allows for different delivery guarantees, such as agreeing on the set of messages received or on delivery ordering. Multicast can be achieved through a single operation instead of sending messages individually to each member, which enhances efficiency by sending once on each link and utilizing hardware multicast when available.\n"
     ]
    }
   ],
   "source": [
    "#pip install llama-index-vector-stores-faiss faiss-cpu\n",
    "import os.path\n",
    "import faiss\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "\n",
    "# check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    Settings.chunk_size = 512\n",
    "    Settings.chunk_overlap = 50\n",
    "    \n",
    "    # Erstellen des FAISS-basierten VectorStore\n",
    "    d=1536\n",
    "    faiss_index = faiss.IndexFlatL2(d)  # 512 ist die Dimension des Embeddings, 1536 für gpt-3.5-embeddings\n",
    "    vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "    # Erstellen des Index mit FAISS als Speichersystem\n",
    "    index = VectorStoreIndex.from_documents(documents, vector_store=vector_store)\n",
    "    #index = VectorStoreIndex.from_documents(documents, )\n",
    "\n",
    "    #index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Either way we can now query the index\n",
    "#query_engine = index.as_query_engine()\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=4)\n",
    "\n",
    "# Frage ausführen\n",
    "now = time()\n",
    "response = query_engine.query(\"What is multicast?\")\n",
    "print(f\"Elapsed: {round(time() - now, 2)}s\")\n",
    "print(response)\n",
    "\n",
    "#query_engine = index.as_query_engine(similarity_top_k=4)\n",
    "#response = query_engine.query(\"Can you please sum up the introduction to multicast?\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bc4ecea-4ac4-421e-9fbd-cc3890903904",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Why do I have to use multicast?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0df03088-78f3-4dc0-80e2-9497f8ac21b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using multicast is beneficial because it allows for efficient communication by sending messages once on each link, utilizing hardware multicast when available. This method is particularly advantageous when transmitting data from one source to multiple destinations, reducing network traffic and improving overall performance.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbfb3d01-ffa4-4327-b828-85d20961b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Can you please complete the following sentence: Multicast communication requires...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49099d1c-99f9-467b-9daa-3d55925be6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordination and agreement.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c4310c9-c39b-4e6a-97c0-7b272edc976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Kannst du mir die Folie ausgeben, auf welcher dieses Ergebnis steht?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdbdef03-e7bf-495d-ba90-c6baa45f90e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 11.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d6f13e3-a86c-437a-b692-b407a5eb75fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ja, ich nutze nur das angebundene PDF zum Abfragen und Antworten.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Nutzt du zum Abfragen und Antworten nur das angebundene PDF?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5bc09f3f-f1c3-42d8-bb86-882ccaab6874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs are used for their ability to store and display information in a consistent format across different devices and platforms.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"pourquoi utilisez-vous les PDF liés ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09068600-8630-4742-86c2-eb952f3e0bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I am sure that Seite 11 was meant.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Sicher, dass du Seite 11 meintest?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678780d-9fc2-41df-b3c3-6758acdabb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can find information about the revision of IP multicast on page 11.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Can you please tell me what information I can find on page 11\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c634650-e6c4-47e9-8390-90bff43f3c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked about the content provided in the context information.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did I asked you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8244b08b-3e42-4337-af80-49a4938e085e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-vector-stores-faiss in c:\\users\\katha\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\katha\\anaconda3\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-vector-stores-faiss) (0.12.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\katha\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2024.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.9.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (10.4.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\katha\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.11.0)\n",
      "Requirement already satisfied: click in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\katha\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\katha\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index-vector-stores-faiss faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab3d66-e54f-4000-b28b-27a5a5469883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
